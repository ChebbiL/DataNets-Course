{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Mode Selection and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### author: Anastasios Giovanidis, 2019-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the TP related to mode selection and cross-validation. We will focus here on regression only, but the techniques can be generalised for classification.\n",
    "We will need to import the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1  (Polynomial Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now work on problems of polynomial regression. As a means of example, we will try to fit data sampled from the following curve:\n",
    "\n",
    "$y = 4 + 2x + 0.5x^2 - 0.07x^3 + \\epsilon$.\n",
    "\n",
    "First create synthetic data for $(x_1,x_2,x_3,y,Er)$. The regression plane (>2 dimensions) is given by the following expression, for $\\ell$ unknown features:\n",
    "\n",
    "$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x + \\hat{\\beta}_2x^2 +\\ldots + \\hat{\\beta}_{\\ell}x^{\\ell}$.\n",
    "\n",
    "**We will use again a multi-linear regression model, to estimate the unknowns.** \n",
    "We propose to use regression models with different polynomial degree, because in reality we do not know which is the appropriate model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "* We start with a linear model of degree $\\ell=3$. Split the total dataset of $n=100$ in a train set and a test set. Plot the least-squares curve and output the $R^2$ value. (use $sigmae = 5$, $xl=0, xh = 10$, $n=200$)\n",
    "\n",
    "* Repeat the process for $\\ell = 1, 2, 3, 6, 9, 16$. \n",
    "\n",
    "(a) plot the $MSE$ value versus $\\ell$ for the Train data. \n",
    "(b) plot the $MSE$ value versur $\\ell$ for the Test data. What do you observe?\n",
    "\n",
    "(c) plot the $R^2$ value versus $\\ell$ for the Train data. \n",
    "(d) plot the $R^2$ value versur $\\ell$ for the Test data. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build synthetic data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "b0 = 4\n",
    "b1 = np.array([2,0.5,-0.07])\n",
    "mue, sigmae = 0, 5\n",
    "xl, xh = 0, 10\n",
    "np.random.seed(199)\n",
    "Er = np.random.normal(mue, sigmae, n)\n",
    "np.random.seed(199)\n",
    "x0 = np.random.uniform(xl,xh,n)\n",
    "x = np.array([x0])\n",
    "x = np.append(x,np.array([x0**2]),axis=0)\n",
    "x = np.append(x,np.array([x0**3]),axis=0)\n",
    "#\n",
    "y = b0 + b1[0]*x[0]+ b1[1]*x[1]+ b1[2]*x[2]+Er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the average $MSE_{test}$ for the data sets:\n",
    "\n",
    "$D_4 = \\left\\{(1,3),\\ (2,4),\\ (3,8),\\ (4,9) \\right\\}$.\n",
    "\n",
    "$D_6 = \\left\\{(1,3),\\ (2,4),\\ (3,8),\\ (4,9), \\ (5,12),\\ (7,14) \\right\\}$.\n",
    "\n",
    "- For these use 3-fold CV method (same as LOOCV).\n",
    "\n",
    "- Repeat with the 2-fold CV method, for the $MSE_{test}$.\n",
    "\n",
    "- Repeat with the Bootstrap method to derive the estimates $(\\hat{\\beta}_0,\\ \\hat{\\beta}_1)$ and their Standard Error (SE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part II (**bonus**): Apply the same method to the data set below for the TV-sales pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/Fishbone/Dropbox/DataNets/ISLbook/Datasets/\"\n",
    "prefix = \"Advertising.csv\"\n",
    "filename1 = directory+prefix\n",
    "dataAd = np.loadtxt(filename1, delimiter=\",\",skiprows=1,usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "pdAd = pd.DataFrame(dataAd, columns=[\"TV\",\"radio\",\"newspaper\",\"sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV = pdAd.iloc[:,0].values\n",
    "#radio = pdAd.iloc[:,1].values\n",
    "#news = pdAd.iloc[:,2].values\n",
    "sales = pdAd.iloc[:,3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to generate all possible LOOCV data splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits = 4\n",
      "TRAIN: X= [2 3 4] y= [4 8 9] TEST: X= [1] y= [3]\n",
      "TRAIN: X= [1 3 4] y= [3 8 9] TEST: X= [2] y= [4]\n",
      "TRAIN: X= [1 2 4] y= [3 4 9] TEST: X= [3] y= [8]\n",
      "TRAIN: X= [1 2 3] y= [3 4 8] TEST: X= [4] y= [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "X = np.array([1,2,3,4])\n",
    "y = np.array([3,4,8,9])\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "print('Number of splits =',loo.get_n_splits(X))\n",
    "for train_index, test_index in loo.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"TRAIN:\", \"X=\", X_train, \"y=\", y_train, \"TEST:\", \"X=\", X_test, \"y=\",  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to generate all possible k-folds CV data splits? We do not have to implement k-fold cross-validation manually. The scikit-learn library provides an implementation that will split a given data sample up.\n",
    "\n",
    "The KFold() scikit-learn class can be used. It takes as arguments the number of splits, whether or not to shuffle the sample, and the seed for the pseudorandom number generator used prior to the shuffle.\n",
    "\n",
    "For example, we can create an instance that splits a dataset into 3 folds, shuffles prior to the split, and uses a value of 1 for the pseudorandom number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits = 3\n",
      "TRAIN: X= [3 4] y= [8 9] TEST: X= [1 2] y= [3 4]\n",
      "TRAIN: X= [1 2 4] y= [3 4 9] TEST: X= [3] y= [8]\n",
      "TRAIN: X= [1 2 3] y= [3 4 8] TEST: X= [4] y= [9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(X)\n",
    "print('Number of splits =',kf.get_n_splits(X)) \n",
    "#KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"TRAIN:\", \"X=\", X_train, \"y=\", y_train, \"TEST:\", \"X=\", X_test, \"y=\",  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use the cross_validate routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "#diabetes = datasets.load_diabetes()\n",
    "#X = diabetes.data[:150]\n",
    "#y = diabetes.target[:150]\n",
    "#\n",
    "# Dataset example with n=4\n",
    "X = np.array([1,2,3,4])\n",
    "X_sc = X[:,np.newaxis]\n",
    "y = np.array([3,4,8,9])\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_neg_mean_squared_error', 'test_r2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Fishbone/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:543: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/Users/Fishbone/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py:543: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(regr, X_sc, y, cv=3, scoring=('r2', 'neg_mean_squared_error'), return_train_score=False)\n",
    "print(sorted(cv_results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-35.  nan  nan]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.         -1.65306122 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_neg_mean_squared_error'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
